1、总共包含多少条数据？
2、共有多少家基金公司？
3、基金公司的规模如何？
4、每家基金公司旗下有多少支基金？
5、旗下基金类型？（偏股？偏债？混合？）
6、旗下各个基金占总规模的比重？

整个项目被分成两部分来执行：一是如何挑选基金；二是如何投资。

一、如何挑选合适基金

1、挑选合适基金公司；
     1.1 统计基金公司的基本信息；
              基金公司规模、基金公司旗下基金总数、旗下老基金总数、老基金规模、基金公司收益（老基金收益），包括最近一个月平均收益、最近三个月平均收益、最近半年平均收益及最近一年平均收益。
     1.2 计算基金公司综合评分。

              （1）score = w0 * corp_size + w1 * funds + w2 * old_funds + w3 * old_fund_size + w4 * mon_profit + w5 * three_mon_profit + w6 * six_mon_profit + w7 * year_profit;
	在实际使用中，公式（1）不太适合
              （2）score = w0 * corp_size + w1 * old_fund_rate + w2 * mon_profit + w3 * three_mon_profit + w4 * six_mon_profit + w5 * year_profit;

              找到评分最好的基金公司，该基金公司就是目标基金公司。
      注：权重系数[w0, w1, w2, w3, w4, w5, w6, w7]根据个人投资风格设定。这是手工设定的，期望未来可以采用人工智能的方法来找到合适的系数。
      疑问：历史基金收益过于平稳对于短线投资一定适合吗？要想从资本市场中获利，只要做到低买高卖即可。或许跌宕起伏才是机会。      

2、从目标基金公司中，选择风险收益比最大的基金作为投资对象
      2.1 如何衡量一只基金的优劣？---> 风险收益比（自定义的）
             一支基金的收益可以通过历史收益数据来量化，那么它的风险该如何量化呢？
             基金根据其投资对象大致可分为：偏股型、偏债性和混合型。
             偏股型基金的投资主要投资对象是股票，其80%以上的基金用于投资股票市场。根据投资占比最大的前10支股票占总投资的比例进一步又将偏股型基金分为：分散型股票基金和集中型股票基金。
      因此，对于偏股型基金，可以通过其投资的股票占比来量化风险。
             对于偏债型基金，其投资的债券数据常常是缺失的，这导致很难通过其投资对象来量化其风险等级。能否利用历史收益数据里的最大回撤来衡量呢？（或者尝试一下历史收益增长与回撤平均值的比值）
             混合型基金。同时通过投资股票占比及最大回撤来量化风险。
      通过风险收益比来挑选基金。从中找到一支风险收益比最低的基金作为投资对象。

二、采用强化学习方法，找到一条合适的策略进行投资，以此来获取最大收益。

1、agent类。agent根据自身持有的金额总数，及环境状态做出决策。
     fund_num = 10
     action_num = 3
     agent的动作空间:  action_space = gym.spaces.Tuple((gym.space.Box(-100, 100, np.float32, shape=(fund_num, )), gym.spaces.Box(0, action_num, np.int, shape=(fund_num, ))))

2、env类。根据agent采取的行动给予反馈。
            在编写环境类时，应该考虑到扩展性。扩展性是一把双刃剑。好的扩展性使得我们可以很方便的添加一个额外的信息到环境中，agent可以根据更多的环境信息做出更好的决策；不好的一面也同样明显，
      就是agent需要更多的训练样本，这样agent训练时间及需要的硬件资源就会加大。
            环境需要给agent提供足够的状态信息，以便agent能够这些信息学到合适的买入（卖出）的时机，以此达到最大化期望累积收益。考虑采用以下指标衡量环境状态：
	   1、N个历史收益数据；
            环境基于的回报一般有两种表示方式：一种是每次的闭市，环境都会根据闭市时的profit给予agent一个奖励，这时候agent的收益每天都会发生变化；一种是只有agent抛售时，环境才会给予agent奖励。
            两种奖励方式当agent执行抛售动作时，其最终奖励是一致的，不同的是这两种方式会使得agent的收敛速度不同。






